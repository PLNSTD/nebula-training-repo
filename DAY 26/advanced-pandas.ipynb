{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üöÄ **Advanced Data Analysis Assignment**\n",
                "\n",
                "Welcome to the next-level assignment! We‚Äôll build on the two previous datasets:\n",
                "1. A **region-based** dataset containing `Region`, `Sales`, and `Transactions`.\n",
                "2. A **time-series** dataset containing daily `Sales` from 2020-01-01 to 2020-12-31.\n",
                "\n",
                "In this notebook, you will:\n",
                "1. Load and explore both datasets.\n",
                "2. Perform advanced grouping and pivoting on the regional data.\n",
                "3. Check correlations and detect potential outliers.\n",
                "4. Conduct advanced time-series analysis (rolling means & seasonal decomposition).\n",
                "5. Provide concise insights from your findings.\n",
                "\n",
                "Let's get started! üéâ\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üß© **Part A: Advanced Analysis on Regional Sales Data**\n",
                "We'll begin by re-generating (or reloading) the regional sales data from your previous assignment."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === Part A: Data Generation (Regional) ===\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "# Seed for reproducibility\n",
                "np.random.seed(0)\n",
                "\n",
                "# Generate random data\n",
                "data_regional = {\n",
                "    'Region': np.random.choice(['North', 'South', 'East', 'West'], size=100),\n",
                "    'Sales': np.random.rand(100) * 1000,  # Sales figures between 0 and 1000\n",
                "    'Transactions': np.random.randint(1, 100, size=100)  # Transactions between 1 and 100\n",
                "}\n",
                "\n",
                "# Create DataFrame\n",
                "df_regional = pd.DataFrame(data_regional)\n",
                "df_regional.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üîç **Task A1: Exploratory Data Analysis**\n",
                "1. Display basic summary statistics for `Sales` and `Transactions`.\n",
                "2. Identify the number of unique regions.\n",
                "3. Check for any missing values.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "# === SOLUTION for Task A1 ===\n",
                "\n",
                "# 1) Basic summary statistics\n",
                "print(df_regional.describe())\n",
                "# 2) Number of unique regions\n",
                "print('\\nNumber of unique regions:', len(pd.unique(df_regional['Region'])))\n",
                "# 3) Check for missing values\n",
                "missing_count = df_regional.isnull().sum()\n",
                "\n",
                "print('\\nMissing values:')\n",
                "print(missing_count)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üíπ **Task A2: Pivot Table & Group Analysis**\n",
                "1. Create a pivot table showing the **average Sales** and **average Transactions** by `Region`.\n",
                "2. Sort the pivot table by the highest average Sales.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 84,
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "             Sales  Transactions\n",
                        "Region                          \n",
                        "East    564.093444     43.684211\n",
                        "North   515.117684     47.320000\n",
                        "South   466.730246     44.708333\n",
                        "West    463.957703     54.937500\n"
                    ]
                }
            ],
            "source": [
                "# === SOLUTION for Task A2 ===\n",
                "# Sort by highest average Sales\n",
                "regions_avg = df_regional[['Region', 'Sales', 'Transactions']].groupby('Region').mean()\n",
                "print(regions_avg)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ‚öóÔ∏è **Task A3: Correlation & Outlier Detection** ‚ö†Ô∏è Optional Challenge\n",
                "1. Calculate the correlation between `Sales` and `Transactions`. Do they appear to be correlated?\n",
                "2. Detect potential outliers in `Sales` using the **IQR** (Interquartile Range) method.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "# === SOLUTION for Task A3 ===\n",
                "# 1) Correlation\n",
                "\n",
                "\n",
                "# 2) Outlier Detection using IQR\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## üìà **Part B: Advanced Time-Series Analysis**\n",
                "Now let's work with the **time-series** dataset from your second assignment. We'll generate (or reload) the data below."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 79,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "# === Part B: Data Generation (Time-Series) ===\n",
                "dates = pd.date_range(start=\"2020-01-01\", end=\"2020-12-31\", freq=\"D\")\n",
                "data_timeseries = {\n",
                "    \"Date\": dates,\n",
                "    \"Sales\": (\n",
                "        np.random.rand(len(dates)) * 200\n",
                "        + np.sin(np.linspace(-3, 3, len(dates))) * 50\n",
                "        + 100\n",
                "    ),\n",
                "}\n",
                "\n",
                "df_timeseries = pd.DataFrame(data_timeseries)\n",
                "# df_timeseries.set_index(\"Date\", inplace=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üîé **Task B1: Quick Exploration**\n",
                "1. Display the first 5 rows.\n",
                "2. Show a statistical summary of the `Sales` column."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 63,
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>Date</th>\n",
                            "      <th>Sales</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>2020-01-01</td>\n",
                            "      <td>187.272347</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>2020-01-02</td>\n",
                            "      <td>119.286455</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>2020-01-03</td>\n",
                            "      <td>163.387520</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>2020-01-04</td>\n",
                            "      <td>93.625235</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>2020-01-05</td>\n",
                            "      <td>250.062909</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "        Date       Sales\n",
                            "0 2020-01-01  187.272347\n",
                            "1 2020-01-02  119.286455\n",
                            "2 2020-01-03  163.387520\n",
                            "3 2020-01-04   93.625235\n",
                            "4 2020-01-05  250.062909"
                        ]
                    },
                    "execution_count": 63,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# === SOLUTION for Task B1 ===\n",
                "# 1) Display first 5 rows of df_timeseries\n",
                "df_timeseries.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 64,
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "count    366.000000\n",
                            "mean     199.975246\n",
                            "std       68.968864\n",
                            "min       53.538327\n",
                            "25%      149.730350\n",
                            "50%      195.446757\n",
                            "75%      250.425475\n",
                            "max      344.621843\n",
                            "Name: Sales, dtype: float64"
                        ]
                    },
                    "execution_count": 64,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# 2) Statistical summary of the 'Sales' column\n",
                "df_timeseries['Sales'].describe()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üìÜ **Task B2: Monthly & Rolling Analysis**\n",
                "1. Calculate monthly average `Sales`.\n",
                "2. Compute a 7-day rolling average to smooth out short-term fluctuations.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 70,
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "                 Sales\n",
                        "Date                  \n",
                        "2020-01-31  178.242190\n",
                        "2020-02-29  187.256332\n",
                        "2020-03-31  149.406804\n",
                        "2020-04-30  135.696461\n",
                        "2020-05-31  174.702597\n",
                        "2020-06-30  204.071624\n",
                        "2020-07-31  200.691383\n",
                        "2020-08-31  234.132734\n",
                        "2020-09-30  236.786944\n",
                        "2020-10-31  264.859310\n",
                        "2020-11-30  224.575244\n",
                        "2020-12-31  216.932296\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "C:\\Users\\PC-Pli\\AppData\\Local\\Temp\\ipykernel_60324\\3877489547.py:5: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
                        "  monthly_avg_sales = df_timeseries.resample(\"M\").mean()\n"
                    ]
                }
            ],
            "source": [
                "# === SOLUTION for Task B2 ===\n",
                "# 1) Monthly average Sales\n",
                "df_timeseries[\"Date\"] = pd.to_datetime(df_timeseries[\"Date\"])\n",
                "df_timeseries.set_index(\"Date\", inplace=True)\n",
                "monthly_avg_sales = df_timeseries.resample(\"M\").mean()\n",
                "print(monthly_avg_sales)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 78,
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "   Region       Sales  Transactions  rolling-7-day-avg\n",
                        "0   North  570.196770            29                NaN\n",
                        "1    West  438.601513             3                NaN\n",
                        "2   South  988.373838            28                NaN\n",
                        "3   North  102.044811            84                NaN\n",
                        "4    West  208.876756            90                NaN\n",
                        "..    ...         ...           ...                ...\n",
                        "95  North  703.888584            74         647.628251\n",
                        "96   East  100.226887            29         600.315172\n",
                        "97   West  919.482614            82         603.591746\n",
                        "98  South  714.241300            59         653.117379\n",
                        "99  North  998.847007             1         733.543391\n",
                        "\n",
                        "[100 rows x 4 columns]\n"
                    ]
                }
            ],
            "source": [
                "# 2) 7-day rolling average\n",
                "df_timeseries['rolling-7-day-avg'] = df_timeseries['Sales'].rolling(window=7).mean()\n",
                "print(df_regional)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üî¨ **Task B3: Day-of-Week Seasonality Analysis (Using Pandas Only)**\n",
                "\n",
                "1. **Extract the day of the week** from the index and store it in a new column (e.g., `DayOfWeek`).\n",
                "2. **Group by** this `DayOfWeek` column to get the **average Sales** for each day of the week.\n",
                "3. **Compare** these daily averages to see if certain days have higher or lower sales.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 83,
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "DayOfWeek\n",
                        "Friday       199.116197\n",
                        "Monday       204.653854\n",
                        "Saturday     189.369580\n",
                        "Sunday       189.386770\n",
                        "Thursday     210.533559\n",
                        "Tuesday      196.933595\n",
                        "Wednesday    211.916607\n",
                        "Name: Sales, dtype: float64\n"
                    ]
                }
            ],
            "source": [
                "# === SOLUTION for Task B3 with Pandas Only ===\n",
                "\n",
                "# 1) Extract day of the week: Monday=0, Sunday=6\n",
                "df_timeseries['DayOfWeek'] = df_timeseries['Date'].dt.day_name()\n",
                "# 2) Group by the day of the week to compute average sales\n",
                "day_of_week_avg = df_timeseries.groupby('DayOfWeek')['Sales'].mean()\n",
                "print(day_of_week_avg)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üìù **Observations & Insights**\n",
                "1. **Regional Data**\n",
                "   - The correlation between `Sales` and `Transactions` is quite low, suggesting they‚Äôre not strongly related in this sample.\n",
                "   - Pivot tables show which region averages the highest Sales, with minimal outliers in `Sales`.\n",
                "\n",
                "2. **Time-Series Data**\n",
                "   - The monthly averages reveal slight fluctuations each month.\n",
                "   - The 7-day rolling average smooths out daily noise.\n",
                "   - Seasonal decomposition indicates a clear weekly seasonal pattern (due to the `np.sin()` component) and an overall trend.\n",
                "\n",
                "---\n",
                "## üèÅ **Assignment Wrap-Up**\n",
                "\n",
                "üéâ **Congratulations!** You‚Äôve:\n",
                "- Built pivot tables and looked for regional trends.\n",
                "- Analyzed correlation and outliers.\n",
                "- Explored monthly averages in time-series data.\n",
                "- Investigated rolling averages and seasonal decomposition.\n",
                "\n",
                "These techniques will provide a solid foundation for more advanced analytical work, including forecasting, anomaly detection, and deeper business intelligence. Keep exploring!\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.6"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
